{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Machine Learning, Artificial Intelligence and Deep Learning\n",
    "\n",
    "\n",
    "## Create Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Virtual environment for Machine Learning\n",
    "\n",
    "Step 1: Update and Upgrade\n",
    ">`sudo apt-get update`; `sudo apt-get -y upgrade`\n",
    "\n",
    "Step 2: Check python3 version\n",
    ">`python3 -V`\n",
    "\n",
    "Step 3:Check / install pip3 latest version\n",
    ">`sudo apt-get install -y python3-pip`\n",
    "\n",
    "Step 4: Don't forget to install following to make your environment more consistent\n",
    ">`sudo apt-get install build-essential libssl-dev libffi-dev python3-dev`\n",
    "\n",
    "\n",
    "````````````````````````````` If you want to create virtual environment then also follow step 5 to 8 ```\n",
    "\n",
    "Step 5: Install python3-venv\n",
    ">`sudo apt-get install -y python3-venv`\n",
    "\n",
    "Step 6: (Important) check and see if xvfb is installed:\n",
    "> Xvfb -help\n",
    "\n",
    "if not, install in main installation (outside virtual environment)\n",
    "> sudo apt-get install xvfb\n",
    "\n",
    "\n",
    "Step 6: (Optional) if you want to keep all environments in separate directory then make directories or else skip\n",
    ">`mkdir directory_env`\n",
    "\n",
    "> `cd directory_env`\n",
    "\n",
    "Step 7: make your environment\n",
    "- `python3 -m venv ML_module`\n",
    "\n",
    "Step 8: activate your environment\n",
    ">`source ML_module/bin/activate`\n",
    "\n",
    "``````````````````````````above are to create virtual environment ````````````````````\n",
    "\n",
    "Step 9: install required libraries\n",
    "\n",
    ">`pip3 install -U numpy pandas matplotlib jupyterlab seaborn jupyter_contrib_nbextensions  scikit-learn xgboost folium statsmodels tqdm`\n",
    "\n",
    "**Note** : You may want o look as jupyter lab as well.\n",
    "\n",
    "Step 10: for Deep Learning (torch is optional)\n",
    "\n",
    ">`pip3 install -U torch torchvision torchaudio`\n",
    "\n",
    "> `pip3 install -U tensorflow==2.15.0`\n",
    "\n",
    "Step 11: for Deepface for computer vision\n",
    "\n",
    "> `pip3 install -U opencv-contrib-python`\n",
    "\n",
    "> `pip3 install -U deepface`\n",
    "\n",
    "> `pip3 install -U cmake`\n",
    "\n",
    "> `pip3 install -U dlib` \n",
    "\n",
    "Step 12: for plotting models and graphs\n",
    " > `pip3 install pydot`\n",
    " \n",
    " > `pip install graphviz`\n",
    " \n",
    " Note you may also need to install `sudo apt-get install -y graphviz libgraphviz-dev` to get it working.\n",
    " \n",
    "  \n",
    " Step 13: install openvino\n",
    " \n",
    " > `pip3 install -U openvino openvino-dev`\n",
    " \n",
    "\n",
    " ```````````````````` Step 14 is for virtual environment ```````````````````\n",
    "\n",
    " Step 14: Freeze the environment\n",
    " > `pip3 freeze -l > ml_requirements.txt`\n",
    "\n",
    " \n",
    "---:######:---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at times, it makes sense to ignore irrelevant warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Basic Directories for housekeeping\n",
    "# set location of input files:\n",
    "inpDir = os.path.join('..', '..', 'input')\n",
    "\n",
    "outDir = os.path.join('..', 'output')\n",
    "\n",
    "# define and set random state \n",
    "RANDOM_STATE = 24\n",
    "\n",
    "np.random.seed(RANDOM_STATE) # Set Random Seed for reproducible  results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adult\n",
      " airplane_60.pkl\n",
      " airplane.pkl\n",
      " airplanes\n",
      " animal_10.zip\n",
      " animals\n",
      " animals_orig.zip\n",
      " animals.zip\n",
      "'APS Failure.zip'\n",
      " aps.zip\n",
      " at.zip\n",
      " basic_operations\n",
      " boston_housing\n",
      " california-housing-prices\n",
      " california-housing-prices.zip\n",
      " cars\n",
      " cars.zip\n",
      " car.zip\n",
      " CelebAMask-HQ-master.zip\n",
      " CelebAMask-HQ.zip\n",
      " cifar-10-batches-py\n",
      " cifar-10-python.tar.gz\n",
      " concrete_data.csv\n",
      " corona_1_02.txt\n",
      " credits.csv\n",
      " custom_img_dir\n",
      " data\n",
      " data.csv.zip\n",
      " digit-recognizer.zip\n",
      " digits.csv\n",
      " digits_mnist\n",
      " digits_mnist.zip\n",
      " dont-overfit-ii.zip\n",
      " dt_sample.csv\n",
      " edu_amaas_sentime_aclImdb_v1.zip\n",
      "'e-shop data and description.zip'\n",
      " eye_disease\n",
      " face_recog\n",
      " faces\n",
      " fashion_mnist\n",
      " fifa_2019.csv\n",
      " fifa_2019.zip\n",
      " fifa21_male2.csv\n",
      " flickr_london.zip\n",
      " flower_photos\n",
      " flower_photos.tgz\n",
      " flower_photos.zip\n",
      " fruits-360-original-size\n",
      " fruits-360-original-size.zip\n",
      " garbage_classification\n",
      " garbage_classification.zip\n",
      " giuliani-mauro-variations.mp3\n",
      " glove.6B.100d.txt\n",
      " glove.6B.100d.txt.zip\n",
      " goodbooks-10k.zip\n",
      " Gowalla.zip\n",
      " Gradient_curve.csv\n",
      " Gradient_curve.xlsx\n",
      " groceries.zip\n",
      " HIGGS.csv.gz\n",
      " household_power_consumption.txt\n",
      " household_power_consumption.zip\n",
      " housing\n",
      " housing_data.csv\n",
      " hpl-maidanov-seibert-python-sc-in-prod-env.pdf\n",
      "'Human Action Recognition'\n",
      "'Human Action Recognition.zip'\n",
      "'human detection dataset'\n",
      " humpback-whale-identification\n",
      " humpback-whale-identification.zip\n",
      " hymenoptera_data.zip\n",
      " imdb_reviews\n",
      " indian_cities.csv\n",
      " international-airline-passengers.csv\n",
      " ionosphere\n",
      " iris\n",
      " iris.csv\n",
      " keywords.csv\n",
      " knn_3b_sample.csv\n",
      " links.csv\n",
      " links_small.csv\n",
      " london.zip\n",
      " machine_learning\n",
      " metadata_clean.csv\n",
      " miml\n",
      " ml-latest.zip\n",
      " mnist.npz\n",
      " model_comparision.csv\n",
      " movielens.zip\n",
      " movies_metadata\n",
      " movies_metadata.csv\n",
      " movies_metadata.zip\n",
      " music.zip\n",
      " netflix_prize_data\n",
      " nfl-health-and-safety-helmet-assignment\n",
      " nfl-health-and-safety-helmet-assignment.zip\n",
      " output.pdf\n",
      "'personality classification'\n",
      " pima-indians-diabetes.data.csv\n",
      " racoon_dataset\n",
      " raghav333-cricket-players-espn\n",
      " raghav333-cricket-players-espn.zip\n",
      " ratings.csv\n",
      " ratings_small.csv\n",
      " Rice_Image_Dataset\n",
      " Rice_Image_Dataset.zip\n",
      " s05_ratings.csv\n",
      " S2_iris.csv\n",
      " S2_movie_rating.csv\n",
      " S2_random_numbers.csv\n",
      " S2_sample_file.txt\n",
      " S2_sample_file_w.txt\n",
      " S2_titanic.csv\n",
      " setup\n",
      " shakespeare.txt\n",
      " simple-examples\n",
      " Social_Network_Ads.csv\n",
      " sonar\n",
      " sorf-op45n05.mid\n",
      " stocks_price_final.csv\n",
      " stocks_price_final.csv.zip\n",
      " student\n",
      " student.txt\n",
      " survey_data.csv\n",
      " t10k-images-idx3-ubyte.gz\n",
      " t10k-labels-idx1-ubyte.gz\n",
      " test_images\n",
      " text_gen\n",
      " time_series_data\n",
      " time_series_data.zip\n",
      " train-images-idx3-ubyte.gz\n",
      " training.1600000.processed.noemoticon.csv\n",
      " training.1600000.processed.noemoticon.csv.zip\n",
      " train-labels-idx1-ubyte.gz\n",
      " twitter_samples\n",
      " txtlists\n",
      " val2017.zip\n",
      " valid_flowers\n",
      " Vehicles-OpenImages.v1-416x416.tensorflow\n",
      " Vehicles-OpenImages.v1-416x416.tensorflow.zip\n",
      " Videos\n",
      " volcano.csv\n",
      " weatherHistory.csv\n",
      " weatherHistory.csv.zip\n",
      " wine\n",
      " wine.data\n",
      " yolo3_demo\n",
      " Zomato.zip\n"
     ]
    }
   ],
   "source": [
    "!ls {inpDir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "094.JPG\t\t\t\tbright_image.JPG_gamma_2.2.jpg\n",
      "bright_image.JPG\t\tcar_2_small.png\n",
      "bright_image.JPG_gamma_0.1.jpg\tdark_image_clahe.png\n",
      "bright_image.JPG_gamma_0.5.jpg\tdark_image_equal.png\n",
      "bright_image.JPG_gamma_1.2.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls {outDir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for Matplotlib\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 12),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large',\n",
    "          'savefig.dpi': 150,\n",
    "          'image.cmap': 'jet',\n",
    "          'image.interpolation': 'none',\n",
    "          'savefig.bbox' : 'tight',\n",
    "          'lines.linewidth' : 2,\n",
    "          'legend.numpoints' : 1\n",
    "         }\n",
    "\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "'''plt.rc('axes', prop_cycle=(\n",
    "    cycler('color', mglearn.plot_helpers.cm_cycle.colors) +\n",
    "    cycler('linestyle', ['-', '-', \"--\", (0, (3, 3)), (0, (1.5, 1.5))])))\n",
    "'''\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 8)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "__all__ = ['np', 'display', 'plt', 'pd', 'sklearn', 'seaborn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Tensorflow environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 19:03:44.803098: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 19:03:45.591644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "## Import Statements\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.22.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.8.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
